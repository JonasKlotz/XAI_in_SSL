{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This Kaggle notebook was used to train our custom SimCLR model.**","metadata":{}},{"cell_type":"code","source":"!pip install lightning lightly","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-13T13:13:41.653732Z","iopub.execute_input":"2023-07-13T13:13:41.655293Z","iopub.status.idle":"2023-07-13T13:14:05.288607Z","shell.execute_reply.started":"2023-07-13T13:13:41.655260Z","shell.execute_reply":"2023-07-13T13:14:05.287423Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting lightning\n  Downloading lightning-2.0.5-py3-none-any.whl (1.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting lightly\n  Downloading lightly-1.4.12-py3-none-any.whl (632 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m632.6/632.6 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: Jinja2<5.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (3.1.2)\nRequirement already satisfied: PyYAML<8.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (5.4.1)\nRequirement already satisfied: arrow<3.0,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.2.3)\nRequirement already satisfied: backoff<4.0,>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.2.1)\nRequirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.12.2)\nRequirement already satisfied: click<10.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (8.1.3)\nCollecting croniter<1.5.0,>=1.3.0 (from lightning)\n  Downloading croniter-1.4.1-py2.py3-none-any.whl (19 kB)\nCollecting dateutils<2.0 (from lightning)\n  Downloading dateutils-0.6.12-py2.py3-none-any.whl (5.7 kB)\nCollecting deepdiff<8.0,>=5.7.0 (from lightning)\n  Downloading deepdiff-6.3.1-py3-none-any.whl (70 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.7/70.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: fastapi<2.0,>=0.92.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.95.1)\nRequirement already satisfied: fsspec<2025.0,>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2023.5.0)\nCollecting inquirer<5.0,>=2.10.0 (from lightning)\n  Downloading inquirer-3.1.3-py3-none-any.whl (18 kB)\nCollecting lightning-cloud>=0.5.37 (from lightning)\n  Downloading lightning_cloud-0.5.37-py3-none-any.whl (596 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m596.7/596.7 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: lightning-utilities<2.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.8.0)\nRequirement already satisfied: numpy<3.0,>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.23.5)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from lightning) (21.3)\nRequirement already satisfied: psutil<7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (5.9.3)\nRequirement already satisfied: pydantic<2.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.10.7)\nCollecting python-multipart<2.0,>=0.0.5 (from lightning)\n  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: requests<4.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.28.2)\nRequirement already satisfied: rich<15.0,>=12.3.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (12.6.0)\nRequirement already satisfied: starlette in /opt/conda/lib/python3.10/site-packages (from lightning) (0.26.1)\nCollecting starsessions<2.0,>=1.2.1 (from lightning)\n  Downloading starsessions-1.3.0-py3-none-any.whl (10 kB)\nRequirement already satisfied: torch<4.0,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.0.0)\nRequirement already satisfied: torchmetrics<2.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.11.4)\nRequirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.64.1)\nRequirement already satisfied: traitlets<7.0,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (5.9.0)\nRequirement already satisfied: typing-extensions<6.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.5.0)\nRequirement already satisfied: urllib3<4.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.26.15)\nRequirement already satisfied: uvicorn<2.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.22.0)\nRequirement already satisfied: websocket-client<3.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.5.1)\nRequirement already satisfied: websockets<13.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (11.0.3)\nRequirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (from lightning) (2.0.2)\nRequirement already satisfied: certifi>=14.05.14 in /opt/conda/lib/python3.10/site-packages (from lightly) (2023.5.7)\nCollecting hydra-core>=1.0.0 (from lightly)\n  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting lightly-utils~=0.0.0 (from lightly)\n  Downloading lightly_utils-0.0.2-py3-none-any.whl (6.4 kB)\nRequirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.10/site-packages (from lightly) (2.8.2)\nRequirement already satisfied: six>=1.10 in /opt/conda/lib/python3.10/site-packages (from lightly) (1.16.0)\nCollecting aenum>=3.1.11 (from lightly)\n  Downloading aenum-3.1.15-py3-none-any.whl (137 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from lightly) (0.15.1)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4<6.0,>=4.8.0->lightning) (2.3.2.post1)\nRequirement already satisfied: pytz in /opt/conda/lib/python3.10/site-packages (from dateutils<2.0->lightning) (2023.3)\nCollecting ordered-set<4.2.0,>=4.0.2 (from deepdiff<8.0,>=5.7.0->lightning)\n  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec<2025.0,>=2022.5.0->lightning) (3.8.4)\nCollecting omegaconf<2.4,>=2.2 (from hydra-core>=1.0.0->lightly)\n  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.0.0->lightly)\n  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: blessed>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from inquirer<5.0,>=2.10.0->lightning) (1.20.0)\nCollecting python-editor>=1.0.4 (from inquirer<5.0,>=2.10.0->lightning)\n  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\nCollecting readchar>=3.0.6 (from inquirer<5.0,>=2.10.0->lightning)\n  Downloading readchar-4.0.5-py3-none-any.whl (8.5 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2<5.0->lightning) (2.1.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from lightly-utils~=0.0.0->lightly) (9.5.0)\nRequirement already satisfied: pyjwt in /opt/conda/lib/python3.10/site-packages (from lightning-cloud>=0.5.37->lightning) (2.6.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->lightning) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<4.0->lightning) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<4.0->lightning) (3.4)\nRequirement already satisfied: commonmark<0.10.0,>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from rich<15.0,>=12.3.0->lightning) (0.9.1)\nRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from rich<15.0,>=12.3.0->lightning) (2.15.1)\nRequirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from starlette->lightning) (3.6.2)\nRequirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from starsessions<2.0,>=1.2.1->lightning) (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.11.0->lightning) (3.12.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.11.0->lightning) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.11.0->lightning) (3.1)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn<2.0->lightning) (0.14.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (1.9.1)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (1.3.1)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette->lightning) (1.3.0)\nRequirement already satisfied: wcwidth>=0.1.4 in /opt/conda/lib/python3.10/site-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning) (0.2.6)\nRequirement already satisfied: setuptools>=41.0 in /opt/conda/lib/python3.10/site-packages (from readchar>=3.0.6->inquirer<5.0,>=2.10.0->lightning) (59.8.0)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<4.0,>=1.11.0->lightning) (1.3.0)\nBuilding wheels for collected packages: antlr4-python3-runtime\n  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144574 sha256=8af70a322e994acd6138233b10fed6b86225d094ea10a83d56e7e6df27eb3053\n  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\nSuccessfully built antlr4-python3-runtime\nInstalling collected packages: python-editor, antlr4-python3-runtime, aenum, readchar, python-multipart, ordered-set, omegaconf, lightly-utils, inquirer, hydra-core, deepdiff, dateutils, croniter, starsessions, lightning-cloud, lightning, lightly\nSuccessfully installed aenum-3.1.15 antlr4-python3-runtime-4.9.3 croniter-1.4.1 dateutils-0.6.12 deepdiff-6.3.1 hydra-core-1.3.2 inquirer-3.1.3 lightly-1.4.12 lightly-utils-0.0.2 lightning-2.0.5 lightning-cloud-0.5.37 omegaconf-2.3.0 ordered-set-4.1.0 python-editor-1.0.4 python-multipart-0.0.6 readchar-4.0.5 starsessions-1.3.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import tarfile\n\nfile_path = \"/kaggle/input/two4two-small/two4two_small.tar.xz\"\noutput_path = \"/kaggle/working/\"\n#simple function to extract the train data\n#tar_file : the path to the .tar file\n#path : the path where it will be extracted\ndef extract(tar_file, path):\n    opened_tar = tarfile.open(tar_file)\n     \n    if tarfile.is_tarfile(tar_file):\n        opened_tar.extractall(path)\n        print(f\"Extracted to {output_path}\")\n    else:\n        print(\"The tar file you entered is not a tar file\")\n        \nextract(file_path, output_path)","metadata":{"execution":{"iopub.status.busy":"2023-07-10T12:38:13.401320Z","iopub.execute_input":"2023-07-10T12:38:13.401785Z","iopub.status.idle":"2023-07-10T12:41:30.520174Z","shell.execute_reply.started":"2023-07-10T12:38:13.401746Z","shell.execute_reply":"2023-07-10T12:41:30.519163Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Extracted to /kaggle/working/\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pytorch_lightning as pl\nimport torch\nimport torch.nn as nn\nimport torchvision\nfrom PIL import Image\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.preprocessing import normalize\n\nfrom lightly.data import LightlyDataset\nfrom lightly.transforms import SimCLRTransform, utils","metadata":{"execution":{"iopub.status.busy":"2023-07-11T08:59:54.513052Z","iopub.execute_input":"2023-07-11T08:59:54.513668Z","iopub.status.idle":"2023-07-11T09:00:13.219341Z","shell.execute_reply.started":"2023-07-11T08:59:54.513628Z","shell.execute_reply":"2023-07-11T09:00:13.218328Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"output_path = \"/kaggle/working/\"\n\ntrain_path = \"/kaggle/working/two4two_small/train\"\ntest_path = \"/kaggle/working/two4two_small/test\"\nval_path = \"/kaggle/working/two4two_small/validation\"","metadata":{"execution":{"iopub.status.busy":"2023-07-11T09:00:13.221116Z","iopub.execute_input":"2023-07-11T09:00:13.221842Z","iopub.status.idle":"2023-07-11T09:00:13.229185Z","shell.execute_reply.started":"2023-07-11T09:00:13.221803Z","shell.execute_reply":"2023-07-11T09:00:13.228181Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"num_workers = 8\nbatch_size = 256\nseed = 1\nmax_epochs = 500\ninput_size = 128\nnum_ftrs = 32","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:57:25.220755Z","iopub.execute_input":"2023-07-11T15:57:25.221104Z","iopub.status.idle":"2023-07-11T15:57:25.226580Z","shell.execute_reply.started":"2023-07-11T15:57:25.221075Z","shell.execute_reply":"2023-07-11T15:57:25.225391Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"pl.seed_everything(seed)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T09:00:13.243223Z","iopub.execute_input":"2023-07-11T09:00:13.243800Z","iopub.status.idle":"2023-07-11T09:00:13.260777Z","shell.execute_reply.started":"2023-07-11T09:00:13.243649Z","shell.execute_reply":"2023-07-11T09:00:13.259453Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}]},{"cell_type":"code","source":"transform = SimCLRTransform(\n    input_size=input_size, vf_prob=0.5, rr_prob=0.5, cj_prob=0.0, random_gray_scale=0.0\n)\n\n# We create a torchvision transformation for embedding the dataset after\n# training\ntest_transform = torchvision.transforms.Compose(\n    [\n        torchvision.transforms.Resize((input_size, input_size)),\n        torchvision.transforms.ToTensor(),\n        torchvision.transforms.Normalize(\n            mean=utils.IMAGENET_NORMALIZE[\"mean\"],\n            std=utils.IMAGENET_NORMALIZE[\"std\"],\n        ),\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T09:00:13.262168Z","iopub.execute_input":"2023-07-11T09:00:13.262602Z","iopub.status.idle":"2023-07-11T09:00:13.269888Z","shell.execute_reply.started":"2023-07-11T09:00:13.262570Z","shell.execute_reply":"2023-07-11T09:00:13.268919Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import os\nimport os\nimport tarfile\nfrom pathlib import Path\n\nfrom torchvision.io import read_image, ImageReadMode\nfrom PIL import Image\n\n\nimport pytorch_lightning as L\nimport pandas as pd\nimport torch\nfrom torch.utils.data import random_split, DataLoader\nfrom torchvision import transforms\n\n\nclass Two4TwoDataset(torch.utils.data.Dataset):\n    def __init__(self,\n                 data_input_dir,\n                 mode='train',\n                 transform=None,\n                 target_transform=None):\n\n        if transform is None:\n            transform = transforms.ToTensor()\n\n        self.root_dir = os.path.join(data_input_dir, mode)\n        self.parameters_file = os.path.join(self.root_dir, 'parameters.jsonl')\n\n        self.parameters = self.create_df(mode)\n        self.id_col_idx = self.parameters.columns.get_loc(\"id\")\n        self.label_col_idx = self.parameters.columns.get_loc(\"label\")\n\n        self.transform = transform\n        self.target_transform = target_transform\n\n    def __len__(self):\n        return len(self.parameters)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        img_name = os.path.join(self.root_dir,\n                                self.parameters.iloc[idx, self.id_col_idx] + '.png')\n        image = Image.open(img_name).convert('RGB')\n        image = self.transform(image)\n\n        mask_name = os.path.join(self.root_dir,\n                                self.parameters.iloc[idx, self.id_col_idx] + '_mask.png')\n        mask = transforms.ToTensor()(Image.open(mask_name).convert('RGB'))\n        \n        label = self.parameters.iloc[idx, self.label_col_idx]\n\n        sample = (image,mask, label)\n\n        return sample\n\n    def create_df(self, mode):\n\n        label_data = pd.read_json(self.parameters_file, lines=True)\n        label_data['label'] = label_data['obj_name'].apply(\n            lambda x: 0 if x == 'sticky' else 1)\n\n        return label_data\n\n\nclass Two4TwoDataModule(L.LightningDataModule):\n    def __init__(self, data_dir: str = \"./\", working_path: str = None, batch_size: int = 32, transform=None, mask_transform=None):\n        super().__init__()\n        self.two2two__predict = None\n        self.two2two_val = None\n        self.two2two_test = None\n        self.two2two_train = None\n        self.data_dir = data_dir\n        self.working_path = working_path\n        self.batch_size = batch_size\n        self.num_workers = 0\n        if transform:\n            self.transform = transform\n        else:\n            self.transform = transforms.Compose([ transforms.Normalize((0.1307,), (0.3081,))])\n        if mask_transform:\n            self.mask_transform = mask_transform\n\n            \n\n    def prepare_data(self):\n        # extract ?\n        file = Path(self.data_dir)\n        if file.is_dir():\n            return\n        elif tarfile.is_tarfile(file):\n            tar = tarfile.open(self.data_dir, \"r\")\n            if self.working_path is None:\n                # remove file ending from data_dir\n                self.data_dir =os.path.splitext(self.data_dir)[0]\n                tar.extractall(path=self.data_dir)\n            else:\n                tar.extractall(path=self.working_path)\n            tar.close()\n        else:\n            raise ValueError(\"Data directory is not a tarfile or directory\")\n\n    def setup(self, stage: str):\n        # Assign train/val datasets for use in dataloaders\n        if stage == \"fit\":\n            self.two2two_train = Two4TwoDataset(self.data_dir, mode='train', transform=self.transform)\n            self.two2two_val = Two4TwoDataset(self.data_dir, mode='validation', transform=self.transform)\n\n        # Assign test dataset for use in dataloader(s)\n        if stage == \"test\":\n            self.two2two_test = Two4TwoDataset(self.data_dir, mode='test', transform=self.transform )\n\n        if stage == \"predict\":\n            self.two2two__predict = Two4TwoDataset(self.data_dir, mode='test', transform=self.transform)\n\n    def train_dataloader(self):\n        return DataLoader(self.two2two_train, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=True, drop_last=True,)\n\n    def val_dataloader(self):\n        return DataLoader(self.two2two_val, batch_size=self.batch_size, num_workers=self.num_workers)\n\n    def test_dataloader(self):\n        return DataLoader(self.two2two_test, batch_size=self.batch_size, num_workers=self.num_workers)\n\n    def predict_dataloader(self):\n        return DataLoader(self.two2two_test, batch_size=self.batch_size, num_workers=self.num_workers)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T09:00:37.815704Z","iopub.execute_input":"2023-07-11T09:00:37.816067Z","iopub.status.idle":"2023-07-11T09:00:37.839153Z","shell.execute_reply.started":"2023-07-11T09:00:37.816036Z","shell.execute_reply":"2023-07-11T09:00:37.838213Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from lightly.loss import NTXentLoss\nfrom lightly.models.modules.heads import SimCLRProjectionHead\n\n\nclass SimCLRModel(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n\n        # create a ResNet backbone and remove the classification head\n        resnet = torchvision.models.resnet18()\n        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n\n        hidden_dim = resnet.fc.in_features\n        self.projection_head = SimCLRProjectionHead(hidden_dim, hidden_dim, 128)\n\n        self.criterion = NTXentLoss()\n\n    def forward(self, x):\n        h = self.backbone(x).flatten(start_dim=1)\n        z = self.projection_head(h)\n        return z\n\n    def training_step(self, batch, batch_idx):\n        (x0, x1), _, _ = batch\n        z0 = self.forward(x0)\n        z1 = self.forward(x1)\n        loss = self.criterion(z0, z1)\n        #self.log(\"train_loss_ssl\", loss)\n        self.log(\"train_loss_ssl\", loss, prog_bar=True, on_step=True, on_epoch=True)\n        return loss\n\n    def configure_optimizers(self):\n        optim = torch.optim.SGD(\n            self.parameters(), lr=7e-2, momentum=0.9, weight_decay=5e-4\n        )\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, max_epochs)\n        return [optim], [scheduler]","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:57:36.140189Z","iopub.execute_input":"2023-07-11T15:57:36.140884Z","iopub.status.idle":"2023-07-11T15:57:36.151972Z","shell.execute_reply.started":"2023-07-11T15:57:36.140852Z","shell.execute_reply":"2023-07-11T15:57:36.150603Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"data_module = Two4TwoDataModule(data_dir=\"/kaggle/working/two4two_small\",\n                                batch_size=batch_size, \n                                transform=transform)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T09:29:42.292697Z","iopub.execute_input":"2023-07-11T09:29:42.293061Z","iopub.status.idle":"2023-07-11T09:29:42.298210Z","shell.execute_reply.started":"2023-07-11T09:29:42.293030Z","shell.execute_reply":"2023-07-11T09:29:42.297306Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"**We had to save checkpoints and rerun multiple times with different account because our daily allowance for computing resources on Kaggle ran out, hence all the different checkpoints and commented out lines.**","metadata":{}},{"cell_type":"code","source":"os.listdir('/kaggle/working/checkpoints')","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:40:25.514653Z","iopub.execute_input":"2023-07-11T15:40:25.515012Z","iopub.status.idle":"2023-07-11T15:40:25.522489Z","shell.execute_reply.started":"2023-07-11T15:40:25.514984Z","shell.execute_reply":"2023-07-11T15:40:25.521562Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"['epoch=40-run-4.ckpt',\n 'epoch=3-run-6-train_loss_ssl=4.299095153808594.ckpt',\n 'epoch=0-run-4.ckpt',\n 'epoch=16-train_loss=0.00.ckpt',\n 'epoch=2-run-7-train_loss_ssl=4.302505016326904.ckpt',\n 'epoch=1-train_loss=0.00.ckpt',\n 'epoch=0-train_loss=0.00.ckpt',\n 'epoch=0-val_loss=0.00.ckpt',\n 'epoch=7-train_loss=0.00.ckpt',\n 'epoch=43-run-5-train_loss_ssl=4.282283782958984.ckpt',\n 'epoch=14-train_loss=0.00.ckpt',\n 'epoch=51-run-7-train_loss_ssl=4.299927711486816.ckpt',\n 'epoch=8-train_loss=0.00.ckpt']"},"metadata":{}}]},{"cell_type":"code","source":"model = SimCLRModel.load_from_checkpoint(output_path + '/checkpoints/epoch=51-run-7-train_loss_ssl=4.299927711486816.ckpt')\n#torch.save(model, output_path + \"full_model4.pth\")","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:57:42.604143Z","iopub.execute_input":"2023-07-11T15:57:42.604818Z","iopub.status.idle":"2023-07-11T15:57:42.898442Z","shell.execute_reply.started":"2023-07-11T15:57:42.604785Z","shell.execute_reply":"2023-07-11T15:57:42.897327Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"#model = SimCLRModel()\n#model = torch.load(output_path + \"full_model.pth\") #load the 20 epoch-trained model by jonas\n#model = SimCLRModel.load_from_checkpoint(output_path + '/checkpoints/epoch=16-train_loss=0.00.ckpt')\n#model = SimCLRModel.load_from_checkpoint(output_path + '/checkpoints/epoch=14-train_loss=0.00.ckpt') \n#model = SimCLRModel.load_from_checkpoint(output_path + '/checkpoints/epoch=8-train_loss=0.00.ckpt') # currently at 20+16+14+8 = 68\n#model = SimCLRModel.load_from_checkpoint(output_path + '/checkpoints/epoch=40-run-4.ckpt') # currently at 20+16+14+8+40 = 108\n#model = SimCLRModel.load_from_checkpoint(output_path + '/checkpoints/epoch=43-run-5-train_loss_ssl=4.282283782958984.ckpt') #108+43 = 151\n#model = SimCLRModel.load_from_checkpoint(output_path + '/checkpoints/epoch=3-run-6-train_loss_ssl=4.299095153808594.ckpt') #151+3 = 154\nmodel = SimCLRModel.load_from_checkpoint(output_path + '/checkpoints/epoch=51-run-7-train_loss_ssl=4.299927711486816.ckpt') #154+51 = 205\ncheckpoint_callback = pl.callbacks.ModelCheckpoint(dirpath='/kaggle/working/checkpoints/',filename='{epoch}-run-8-{train_loss_ssl}') #increase index at earch run!!!\ntrainer = pl.Trainer(max_epochs=max_epochs, devices=1, accelerator=\"gpu\", callbacks=[checkpoint_callback])\ntrainer.fit(model, data_module)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:51:05.178763Z","iopub.execute_input":"2023-07-11T16:51:05.179143Z","iopub.status.idle":"2023-07-11T16:58:07.017093Z","shell.execute_reply.started":"2023-07-11T16:51:05.179111Z","shell.execute_reply":"2023-07-11T16:58:07.015809Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: UserWarning: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n  rank_zero_warn(\"You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\")\n/opt/conda/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /kaggle/working/checkpoints exists and is not empty.\n  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0287ecf589794476a5122b59f496a997"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model, output_path + \"full_model3.pth\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
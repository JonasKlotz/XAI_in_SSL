{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhC-0XtDl7bk"
   },
   "source": [
    "# Getting necessary requirements for the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "liV47DsXhpfN"
   },
   "source": [
    "# Requried imports and helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MlZXv3bphr1-"
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kKN4GEq1hmzv"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6q_L9lOWhmvl",
    "outputId": "13234a04-9208-40b6-cb0d-4de0ce56fb86"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.transforms.functional import pil_to_tensor\n",
    "from torchvision.transforms import ToTensor, Normalize, Resize\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "\n",
    "import pl_bolts\n",
    "from pl_bolts.models.autoencoders import VAE\n",
    "from pl_bolts.models.self_supervised import SimCLR, SwAV\n",
    "import torchvision\n",
    "\n",
    "from captum.attr import IntegratedGradients, GradientShap\n",
    "\n",
    "import tqdm.notebook as tqdm\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mbWq-YP3FR5P"
   },
   "outputs": [],
   "source": [
    "# Load the Explanation method COCOA and Feature Attribution method\n",
    "from contrastive_corpus_similarity import ContrastiveCorpusSimilarity\n",
    "from rise import RISE\n",
    "from utils import get_black_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tulNOGZDmOCi"
   },
   "source": [
    "# Get the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dliqwYcgR-3q"
   },
   "outputs": [],
   "source": [
    "from lightly.loss import NTXentLoss\n",
    "from lightly.models.modules.heads import SimCLRProjectionHead\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class SimCLRModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # create a ResNet backbone and remove the classification head\n",
    "        resnet = torchvision.models.resnet18()\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "\n",
    "        hidden_dim = resnet.fc.in_features\n",
    "        self.projection_head = SimCLRProjectionHead(hidden_dim, hidden_dim, 128)\n",
    "\n",
    "        self.criterion = NTXentLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.backbone(x).flatten(start_dim=1)\n",
    "        z = self.projection_head(h)\n",
    "        return z\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        (x0, x1), _, _ = batch\n",
    "        z0 = self.forward(x0)\n",
    "        z1 = self.forward(x1)\n",
    "        loss = self.criterion(z0, z1)\n",
    "        self.log(\"train_loss_ssl\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.SGD(\n",
    "            self.parameters(), lr=6e-2, momentum=0.9, weight_decay=5e-4\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, max_epochs)\n",
    "        return [optim], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_sBYm7Frhmof"
   },
   "outputs": [],
   "source": [
    "#load some models\n",
    "\n",
    "def load_supervised():\n",
    "    supervised = torchvision.models.resnet50(pretrained=True)\n",
    "    modules = list(supervised.children())[:-1]\n",
    "    supervised = nn.Sequential(*modules, nn.Flatten()).to(DEVICE)\n",
    "    supervised.eval()\n",
    "    return supervised\n",
    "\n",
    "def load_swav():\n",
    "    swav_weight_path = 'https://pl-bolts-weights.s3.us-east-2.amazonaws.com/swav/swav_imagenet/swav_imagenet.pth.tar'\n",
    "    swav = SwAV.load_from_checkpoint(swav_weight_path, strict=False)\n",
    "    swav = swav.to(DEVICE)\n",
    "    swav.eval()\n",
    "    return swav\n",
    "\n",
    "\n",
    "def load_simclr_custom():\n",
    "    simclr = torch.load('./full_model3.pth')\n",
    "    simclr.eval()\n",
    "    return simclr\n",
    "\n",
    "def load_vae():\n",
    "    vae = VAE(input_height=IMAGE_SIZE).from_pretrained('stl10-resnet18')\n",
    "    modules = list(vae.children())[:-3]\n",
    "    vae = nn.Sequential(*modules, nn.Flatten()).to(DEVICE)\n",
    "    vae.eval()\n",
    "    return vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YsuPGZmiY3LL"
   },
   "outputs": [],
   "source": [
    "def load_simclr():\n",
    "    simclr_weight_path = 'https://pl-bolts-weights.s3.us-east-2.amazonaws.com/simclr/bolts_simclr_imagenet/simclr_imagenet.ckpt'\n",
    "    simclr = SimCLR.load_from_checkpoint(simclr_weight_path, strict=False)\n",
    "    simclr = simclr.to(DEVICE)\n",
    "    simclr.eval()\n",
    "    return simclr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EyBVs9P_hmmN",
    "outputId": "6ca7ef97-5aec-4514-f095-73d57be6db6b"
   },
   "outputs": [],
   "source": [
    "#dowload models\n",
    "\n",
    "load_supervised()\n",
    "load_swav()\n",
    "load_simclr()\n",
    "load_vae()\n",
    "load_simclr_custom()\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PMcrr6FAhmjs"
   },
   "outputs": [],
   "source": [
    "def load_img_from_drive(img_name, shape=IMAGE_SIZE):\n",
    "    # loads two4two images from personal drive \n",
    "    img = Image.open('../242/test/{}'.format(img_name)).convert('RGB')\n",
    "\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((shape, shape)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                         std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    x = transform(img).unsqueeze(0)\n",
    "\n",
    "    return x.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xETCoGvHhmXu"
   },
   "outputs": [],
   "source": [
    "def load_mask_from_drive(mask_name, shape=IMAGE_SIZE):\n",
    "  #loads two4two masks from personal drive (after they have been uploaded and unzipped)\n",
    "    mask = cv2.imread('../242/test/{}'.format(mask_name))\n",
    "\n",
    "    target_transform = transforms.Compose([transforms.ToPILImage(), transforms.ToTensor(), torchvision.transforms.Resize((shape, shape))])\n",
    "    mask = target_transform(mask).sum(dim=0).unsqueeze(dim=0)\n",
    "\n",
    "    mask = torch.where(mask > 0, torch.tensor(1), torch.tensor(0))\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tV9acHKjiBjs"
   },
   "outputs": [],
   "source": [
    "def to_np(x):\n",
    "    return x.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vKpvlcZiCz2"
   },
   "source": [
    "# Get Baseline method for samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a92mEAjgjBOm"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "get_baseline = partial(\n",
    "    get_black_baseline\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9d1iEOmin-g"
   },
   "source": [
    "# Get Reference and Foil set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nGbe9HjOipa4"
   },
   "outputs": [],
   "source": [
    "# NOTE: the images are structured according to\n",
    "# ./mixed/mixed/<image_name>.png\n",
    "data_path = \"./mixed/\"\n",
    "\n",
    "# Define the transformations to apply to the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize the images to a specific size\n",
    "    transforms.ToTensor(),  # Convert the images to tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225]),\n",
    "\n",
    "])\n",
    "\n",
    "# Load the images from the directory using the ImageFolder dataset\n",
    "dataset = ImageFolder(root=data_path, transform=transform)\n",
    "\n",
    "# Create a data loader to iterate over the dataset in batches\n",
    "batch_size = 32\n",
    "data_loader_ref = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uIdLW0Q7ipYN"
   },
   "outputs": [],
   "source": [
    "# NOTE: the images are structured according to\n",
    "# ./noise/noise/<image_name>.png\n",
    "data_path = \"./noise/\"\n",
    "\n",
    "# Define the transformations to apply to the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize the images to a specific size\n",
    "    transforms.ToTensor(),  # Convert the images to tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                      std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load the images from the directory using the ImageFolder dataset\n",
    "dataset = ImageFolder(root=data_path, transform=transform)\n",
    "\n",
    "# Create a data loader to iterate over the dataset in batches\n",
    "batch_size = 32\n",
    "data_loader_foil = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Contrastive Corpus Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "285O_XF8kFmG",
    "outputId": "517cf2a9-6aa6-4387-d4cc-b7d630f49acf"
   },
   "outputs": [],
   "source": [
    "model_super = load_supervised()\n",
    "model_sim = load_simclr()\n",
    "model_swav = load_swav()\n",
    "model_vae = load_vae()\n",
    "model_sim_custom = load_simclr_custom()\n",
    "\n",
    "ccs_super = ContrastiveCorpusSimilarity(\n",
    "        encoder=model_super.to(DEVICE),\n",
    "        corpus_dataloader=data_loader_ref,\n",
    "        foil_dataloader=data_loader_foil,\n",
    "        normalize=True,\n",
    "        batch_size=32\n",
    "      )\n",
    "\n",
    "ccs_sim = ContrastiveCorpusSimilarity(\n",
    "        encoder=model_sim.to(DEVICE),\n",
    "        corpus_dataloader=data_loader_ref,\n",
    "        foil_dataloader=data_loader_foil,\n",
    "        normalize=True,\n",
    "        batch_size=32,\n",
    "      )\n",
    "\n",
    "ccs_swav = ContrastiveCorpusSimilarity(\n",
    "        encoder=model_swav.to(DEVICE),\n",
    "        corpus_dataloader=data_loader_ref,\n",
    "        foil_dataloader=data_loader_foil,\n",
    "        normalize=True,\n",
    "        batch_size=32\n",
    "      )\n",
    "\n",
    "ccs_vae = ContrastiveCorpusSimilarity(\n",
    "        encoder=model_vae.to(DEVICE),\n",
    "        corpus_dataloader=data_loader_ref,\n",
    "        foil_dataloader=data_loader_foil,\n",
    "        normalize=True,\n",
    "        batch_size=32\n",
    "      )\n",
    "\n",
    "ccs_sim_custom = ContrastiveCorpusSimilarity(\n",
    "        encoder=model_sim_custom.to(DEVICE),\n",
    "        corpus_dataloader=data_loader_ref,\n",
    "        foil_dataloader=data_loader_foil,\n",
    "        normalize=True,\n",
    "        batch_size=32\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a_9DQ_VglZjX"
   },
   "outputs": [],
   "source": [
    "ccs_list = [ccs_super, ccs_sim, ccs_swav, ccs_vae, ccs_sim_custom]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLRg4hVuFR51"
   },
   "source": [
    "# RISE Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "id": "BKImfKcBFR51",
    "outputId": "158cd7ce-01bf-438b-91d6-8a46889a780a"
   },
   "outputs": [],
   "source": [
    "list_images = sorted(os.listdir('../242/test'))\n",
    "\n",
    "model_name_list = ['Supervised', 'SimCLR', 'SwAV', 'VAE']#, 'Custom SimCLR']\n",
    "model_list = [load_supervised, load_simclr, load_swav, load_vae]#, load_simclr_custom]\n",
    "mask_bs = 100\n",
    "num_batches = 30\n",
    "\n",
    "tk_list = []\n",
    "pg_list = []\n",
    "rra_list = []\n",
    "\n",
    "print(model_name_list)\n",
    "#we have a total of 5k images and 5k masks for the images\n",
    "#iterate over images + masks\n",
    "for i in range(0,4650):\n",
    "    attr_list = []\n",
    "    tk_indv_list = []\n",
    "    pg_indv_list = []\n",
    "    rra_indiv_list = []\n",
    "    image_name = list_images[i*2]\n",
    "    mask_name = list_images[(i*2)+1]\n",
    "    x = load_img_from_drive(image_name)\n",
    "    baseline = get_baseline(x)\n",
    "    mask = load_mask_from_drive(mask_name)\n",
    "\n",
    "    #iterate over models\n",
    "    for model_loader, model_name, ccs in zip(model_list, model_name_list, ccs_list):\n",
    "\n",
    "#         model = model_loader()\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            rise = RISE(ccs)\n",
    "            attr = rise.attribute(\n",
    "                    x.cuda(),\n",
    "                    (8,8),\n",
    "                    baselines=baseline.cuda(),\n",
    "                    mask_prob=0.5,\n",
    "                    n_samples=3000,\n",
    "                    normalize_by_mask_prob=True,\n",
    "                )\n",
    "\n",
    "        attr_list.append(attr)\n",
    "\n",
    "\n",
    "  #iterate over models' results\n",
    "    for j in range(len(model_list)):\n",
    "        s=to_np(mask.squeeze())\n",
    "        a=to_np(attr_list[j].mean(dim=1).cpu().detach().squeeze())\n",
    "\n",
    "        k=1000\n",
    "        #prepare shapes\n",
    "        s = s.astype(bool)\n",
    "        top_k_binary_mask = np.zeros(a.shape)\n",
    "\n",
    "        #top-k intersection\n",
    "        #sort and create masks\n",
    "        sorted_indices = np.argsort(a, axis=None)\n",
    "        np.put_along_axis(top_k_binary_mask, sorted_indices[-k:], 1, axis=None)\n",
    "        top_k_binary_mask = top_k_binary_mask.astype(bool)\n",
    "        tki = 1.0 / k * np.sum(np.logical_and(s, top_k_binary_mask))\n",
    "\n",
    "        #pointing game\n",
    "        #find indices with max value\n",
    "        a_pg = a.copy().flatten()\n",
    "        s_pg = to_np(mask.squeeze()).flatten().astype(bool)\n",
    "        max_index = np.argwhere(a_pg == np.max(a_pg))\n",
    "        #check if maximum of explanation is on target object class.\n",
    "        hit = np.any(s_pg[max_index])\n",
    "\n",
    "        #relevance rank accuracy\n",
    "        s = to_np(mask.squeeze())\n",
    "        s = np.where(s.flatten().astype(bool))[0]\n",
    "        #size of the ground truth mask\n",
    "        n = len(s)\n",
    "        #sort in descending order\n",
    "        a_sorted = np.argsort(a.flatten())[-int(n) :]\n",
    "        #calculate hits\n",
    "        hits = len(np.intersect1d(s, a_sorted))\n",
    "        if hits != 0:\n",
    "            rank_accuracy = hits / float(n)\n",
    "        else:\n",
    "            rank_accuracy = 0.0\n",
    "\n",
    "        tk_indv_list.append(tki)\n",
    "        pg_indv_list.append(np.float(hit))\n",
    "        rra_indiv_list.append(rank_accuracy)\n",
    "    tk_list.append(tk_indv_list)\n",
    "    pg_list.append(pg_indv_list)\n",
    "    rra_list.append(rra_indiv_list)\n",
    "    if i % 1 == 0: #print rolling mean after every **1** images processed.\n",
    "        print(i)\n",
    "        print('Pointing Game:')\n",
    "        print(np.array(pg_list).mean(axis=0))\n",
    "        print('Top-K:')\n",
    "        print(np.array(tk_list).mean(axis=0))\n",
    "        print('Relevance Rank Acc.:')\n",
    "        print(np.array(rra_list).mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAinxNbpFR52"
   },
   "source": [
    "# Integrated Gradients Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 939
    },
    "id": "0x-dDIYNbMwF",
    "outputId": "e741fde0-eb4b-48cc-d54d-35d6a7417dea"
   },
   "outputs": [],
   "source": [
    "list_images = sorted(os.listdir('../242/test'))\n",
    "\n",
    "model_name_list = ['Supervised', 'SimCLR', 'SwAV', 'VAE', 'Custom SimCLR']\n",
    "model_list = [load_supervised, load_simclr, load_swav, load_vae, load_simclr_custom]\n",
    "mask_bs = 100\n",
    "num_batches = 30\n",
    "\n",
    "tk_list = []\n",
    "pg_list = []\n",
    "rra_list = []\n",
    "\n",
    "print(model_name_list)\n",
    "#we have a total of 5k images and 5k masks for the images\n",
    "#iterate over images + masks\n",
    "for i in range(0,4650):\n",
    "    attr_list = []\n",
    "    tk_indv_list = []\n",
    "    pg_indv_list = []\n",
    "    rra_indiv_list = []\n",
    "    image_name = list_images[i*2]\n",
    "    mask_name = list_images[(i*2)+1]\n",
    "    x = load_img_from_drive(image_name)\n",
    "    baseline = get_baseline(x)\n",
    "    mask = load_mask_from_drive(mask_name)\n",
    "\n",
    "    #iterate over models\n",
    "    for model_loader, model_name, ccs in zip(model_list, model_name_list, ccs_list):\n",
    "\n",
    "#         model = model_loader()\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            ig = IntegratedGradients(ccs)\n",
    "            attr = ig.attribute(\n",
    "                    x.cuda(),\n",
    "                    baselines=baseline.cuda(),\n",
    "                )\n",
    "\n",
    "        attr_list.append(attr)\n",
    "\n",
    "\n",
    "  #iterate over models' results\n",
    "    for j in range(len(model_list)):\n",
    "        s=to_np(mask.squeeze())\n",
    "        a=to_np(attr_list[j].mean(dim=1).cpu().detach().squeeze())\n",
    "\n",
    "        k=1000\n",
    "        #prepare shapes\n",
    "        s = s.astype(bool)\n",
    "        top_k_binary_mask = np.zeros(a.shape)\n",
    "\n",
    "        #top-k intersection\n",
    "        #sort and create masks\n",
    "        sorted_indices = np.argsort(a, axis=None)\n",
    "        np.put_along_axis(top_k_binary_mask, sorted_indices[-k:], 1, axis=None)\n",
    "        top_k_binary_mask = top_k_binary_mask.astype(bool)\n",
    "        tki = 1.0 / k * np.sum(np.logical_and(s, top_k_binary_mask))\n",
    "\n",
    "        #pointing game\n",
    "        #find indices with max value\n",
    "        a_pg = a.copy().flatten()\n",
    "        s_pg = to_np(mask.squeeze()).flatten().astype(bool)\n",
    "        max_index = np.argwhere(a_pg == np.max(a_pg))\n",
    "        #check if maximum of explanation is on target object class.\n",
    "        hit = np.any(s_pg[max_index])\n",
    "\n",
    "        #relevance rank accuracy\n",
    "        s = to_np(mask.squeeze())\n",
    "        s = np.where(s.flatten().astype(bool))[0]\n",
    "        #size of the ground truth mask\n",
    "        n = len(s)\n",
    "        #sort in descending order\n",
    "        a_sorted = np.argsort(a.flatten())[-int(n) :]\n",
    "        #calculate hits\n",
    "        hits = len(np.intersect1d(s, a_sorted))\n",
    "        if hits != 0:\n",
    "            rank_accuracy = hits / float(n)\n",
    "        else:\n",
    "            rank_accuracy = 0.0\n",
    "\n",
    "        tk_indv_list.append(tki)\n",
    "        pg_indv_list.append(np.float(hit))\n",
    "        rra_indiv_list.append(rank_accuracy)\n",
    "    tk_list.append(tk_indv_list)\n",
    "    pg_list.append(pg_indv_list)\n",
    "    rra_list.append(rra_indiv_list)\n",
    "    if i % 1 == 0: #print rolling mean after every **1** images processed.\n",
    "        print(i)\n",
    "        print('Pointing Game:')\n",
    "        print(np.array(pg_list).mean(axis=0))\n",
    "        print('Top-K:')\n",
    "        print(np.array(tk_list).mean(axis=0))\n",
    "        print('Relevance Rank Acc.:')\n",
    "        print(np.array(rra_list).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Dm4Y3OLdCg1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1En98gZdEdz"
   },
   "source": [
    "# GradientShap Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "JGi9IiRedDxZ",
    "outputId": "7d50294f-8b8f-4d2d-f230-ec3f5d07fd1b"
   },
   "outputs": [],
   "source": [
    "list_images = sorted(os.listdir('../242/test'))\n",
    "\n",
    "model_name_list = ['Supervised', 'SimCLR', 'SwAV', 'VAE', 'Custom SimCLR']\n",
    "model_list = [load_supervised, load_simclr, load_swav, load_vae]#, load_simclr_custom]\n",
    "mask_bs = 100\n",
    "num_batches = 30\n",
    "\n",
    "tk_list = []\n",
    "pg_list = []\n",
    "rra_list = []\n",
    "\n",
    "print(model_name_list)\n",
    "#we have a total of 5k images and 5k masks for the images\n",
    "#iterate over images + masks\n",
    "for i in range(0,4650):\n",
    "    attr_list = []\n",
    "    tk_indv_list = []\n",
    "    pg_indv_list = []\n",
    "    rra_indiv_list = []\n",
    "    image_name = list_images[i*2]\n",
    "    mask_name = list_images[(i*2)+1]\n",
    "    x = load_img_from_drive(image_name)\n",
    "    baseline = get_baseline(x)\n",
    "    mask = load_mask_from_drive(mask_name)\n",
    "\n",
    "    #iterate over models\n",
    "    for model_loader, model_name, ccs in zip(model_list, model_name_list, ccs_list):\n",
    "\n",
    "#         model = model_loader()\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            gs = GradientShap(ccs)\n",
    "            attr = gs.attribute(\n",
    "                    x.cuda(),\n",
    "                    baselines=baseline.cuda(),\n",
    "                    n_samples=50,\n",
    "                    stdevs=0.2\n",
    "                )\n",
    "\n",
    "        attr_list.append(attr)\n",
    "\n",
    "\n",
    "    #iterate over models' results\n",
    "    for j in range(len(model_list)):\n",
    "        s=to_np(mask.squeeze())\n",
    "        a=to_np(attr_list[j].mean(dim=1).cpu().detach().squeeze())\n",
    "\n",
    "        k=1000\n",
    "        #prepare shapes\n",
    "        s = s.astype(bool)\n",
    "        top_k_binary_mask = np.zeros(a.shape)\n",
    "\n",
    "        #top-k intersection\n",
    "        #sort and create masks\n",
    "        sorted_indices = np.argsort(a, axis=None)\n",
    "        np.put_along_axis(top_k_binary_mask, sorted_indices[-k:], 1, axis=None)\n",
    "        top_k_binary_mask = top_k_binary_mask.astype(bool)\n",
    "        tki = 1.0 / k * np.sum(np.logical_and(s, top_k_binary_mask))\n",
    "\n",
    "        #pointing game\n",
    "        #find indices with max value\n",
    "        a_pg = a.copy().flatten()\n",
    "        s_pg = to_np(mask.squeeze()).flatten().astype(bool)\n",
    "        max_index = np.argwhere(a_pg == np.max(a_pg))\n",
    "        #check if maximum of explanation is on target object class.\n",
    "        hit = np.any(s_pg[max_index])\n",
    "\n",
    "        #relevance rank accuracy\n",
    "        s = to_np(mask.squeeze())\n",
    "        s = np.where(s.flatten().astype(bool))[0]\n",
    "        #size of the ground truth mask\n",
    "        n = len(s)\n",
    "        #sort in descending order\n",
    "        a_sorted = np.argsort(a.flatten())[-int(n) :]\n",
    "        #calculate hits\n",
    "        hits = len(np.intersect1d(s, a_sorted))\n",
    "        if hits != 0:\n",
    "            rank_accuracy = hits / float(n)\n",
    "        else:\n",
    "            rank_accuracy = 0.0\n",
    "\n",
    "        tk_indv_list.append(tki)\n",
    "        pg_indv_list.append(np.float(hit))\n",
    "        rra_indiv_list.append(rank_accuracy)\n",
    "    tk_list.append(tk_indv_list)\n",
    "    pg_list.append(pg_indv_list)\n",
    "    rra_list.append(rra_indiv_list)\n",
    "    if i % 1 == 0: #print rolling mean after every **1** images processed.\n",
    "        print(i)\n",
    "        print('Pointing Game:')\n",
    "        print(np.array(pg_list).mean(axis=0))\n",
    "        print('Top-K:')\n",
    "        print(np.array(tk_list).mean(axis=0))\n",
    "        print('Relevance Rank Acc.:')\n",
    "        print(np.array(rra_list).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KlxdP1nVFR56"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
